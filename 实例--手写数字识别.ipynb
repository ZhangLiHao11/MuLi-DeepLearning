{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "682b01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import mnist#导入pytorch内置的mnist数据\n",
    "#导入预处理模块\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "#导入nn及优化器\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "#定义一些超参数\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "learning_rate = 0.01\n",
    "num_epoches = 5\n",
    "lr = 0.01\n",
    "momentum = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29d5d0",
   "metadata": {},
   "source": [
    "下载数据并预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d5c329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#定义预处理函数，这些预处理依次放在Compose函数中。\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])#transforms.Compose可以把一些转换函数组合在一起\n",
    "#Normalize([0.5], [0.5])对张量进行归一化，这里两个0.5分别表示对张量进行归一化的全局平均值和方差。因图像是灰色的只有一个通道，如果有多个通道，需要有多个数字，如三个通道，应该是Normalize([m1,m2,m3], [n1,n2,n3])\n",
    "train_dataset = mnist.MNIST('../data', train=True, transform=transform, download=True)\n",
    "test_dataset = mnist.MNIST('../data', train=False, transform=transform)\n",
    "#dataloader是一个可迭代对象，可以使用迭代器一样使用\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7579a",
   "metadata": {},
   "source": [
    "可视化源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26b299c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "examples = enumerate(test_loader)#enumerate() 函数用于将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "batch_idx, (example_data, example_targets) = next(examples)#next() 返回迭代器的下一个项目\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15360d81",
   "metadata": {},
   "source": [
    "构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a067431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net(784, 300, 100, 10)\n",
    "model.to(device)\n",
    "\n",
    "#定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7ec23",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "657ceefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train Loss: 1.0376, Train Acc: 0.7784, Test Loss: 0.5516, Test Acc: 0.8991\n",
      "epoch: 1, Train Loss: 0.4858, Train Acc: 0.8974, Test Loss: 0.3567, Test Acc: 0.9249\n",
      "epoch: 2, Train Loss: 0.3518, Train Acc: 0.9180, Test Loss: 0.2774, Test Acc: 0.9375\n",
      "epoch: 3, Train Loss: 0.2874, Train Acc: 0.9309, Test Loss: 0.2319, Test Acc: 0.9444\n",
      "epoch: 4, Train Loss: 0.2436, Train Acc: 0.9395, Test Loss: 0.2000, Test Acc: 0.9511\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    #动态修改参数学习率\n",
    "    if epoch%5==0:\n",
    "        optimizer.param_groups[0]['lr']*=0.1\n",
    "    for img, label in train_loader:\n",
    "        img=img.to(device)\n",
    "        label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        #前向传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        #反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #记录误差\n",
    "        train_loss += loss.item()\n",
    "        #计算分类的准确率\n",
    "        _,pred = out.max(1)\n",
    "        num_correct =(pred == label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        train_acc += acc\n",
    "    \n",
    "    losses.append(train_loss / len(train_loader))\n",
    "    acces.append(train_acc / len(train_loader))\n",
    "    #在测试集上检验效果\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    #将模型改为预测模式\n",
    "    model.eval()\n",
    "    for img, label in test_loader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        #记录误差\n",
    "        eval_loss += loss.item()\n",
    "        #记录准确率\n",
    "        _,pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / img.shape[0]\n",
    "        eval_acc += acc\n",
    "        \n",
    "    eval_losses.append(eval_loss / len(test_loader))\n",
    "    eval_acces.append(eval_acc / len(test_loader))\n",
    "    print('epoch: {}, Train Loss: {:.4f}, Train Acc: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.4f}'\n",
    "          .format(epoch, train_loss / len(train_loader), train_acc / len(train_loader), \n",
    "                     eval_loss / len(test_loader), eval_acc / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d48e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('train loss')\n",
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.legend(['Train Loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a05e5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"fc_trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5975aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label       predicted\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (28x28 and 784x300)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4024d0596928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-4024d0596928>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-c7824d9d2549>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anacond\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28x28 and 784x300)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyMnistDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "\n",
    "        self.myMnistPath = root\n",
    "        self.imagesData = []\n",
    "        self.labelsData = []\n",
    "        self.labelsDict = {}\n",
    "        self.trans = transform\n",
    "\n",
    "        self.loadLabelsDate()\n",
    "        self.loadImageData()\n",
    "\n",
    "    # 读取标签txt文件，并生成字典\n",
    "    def loadLabelsDate(self):\n",
    "        labelsPath = os.path.join(self.myMnistPath, \"labels\", \"labels.txt\")\n",
    "        f = open(labelsPath)\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            name = line.split(' ')[0]\n",
    "            label = line.split(' ')[1]\n",
    "            self.labelsDict[name] = int(label)\n",
    "\n",
    "    # 读取手写图片数据，并将图片数据和对应的标签组合在一起\n",
    "    def loadImageData(self):\n",
    "        imagesFolderPath = os.path.join(self.myMnistPath, 'images')\n",
    "        imageFiles = os.listdir(imagesFolderPath)\n",
    "\n",
    "        for imageName in imageFiles:\n",
    "            imagePath = os.path.join(imagesFolderPath, imageName)\n",
    "            image = Image.open(imagePath)\n",
    "            grayImage = image.convert(\"L\")\n",
    "\n",
    "            imageTensor = self.trans(grayImage)\n",
    "            self.imagesData.append(imageTensor)\n",
    "\n",
    "            self.labelsData.append(self.labelsDict[imageName])\n",
    "\n",
    "        self.labelsData = torch.Tensor(self.labelsData)\n",
    "\n",
    "    # 重写魔法函数\n",
    "    def __getitem__(self, index):\n",
    "        return self.imagesData[index], self.labelsData[index]\n",
    "\n",
    "    # 重写魔法函数\n",
    "    def __len__(self):\n",
    "        return len(self.labelsData)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([28, 28]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 载入自己的数据集\n",
    "dataset = MyMnistDataset(root='../data/my_mnist_dateset', transform=transform)\n",
    "test_loader = DataLoader(dataset=dataset, shuffle=False)\n",
    "\n",
    "# 生成全连接神经网络并载入训练好的模型\n",
    "model = Net(784, 300, 100, 10)\n",
    "model.load_state_dict(torch.load(\"./fc_trained_model.pth\"))\n",
    "\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(\"label       predicted\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print(\"{}          {}\".format(int(labels.item()), predicted.data.item()))\n",
    "\n",
    "        print('FC trained model: accuracy on mymnist set:%d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a8fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ccc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
