{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676715ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/10] loss:2.295:   1%|▍                                                   | 9/938 [00:00<00:11, 83.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[1/10] loss:2.298: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.81it/s]\n",
      "validate epoch[1/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 128.56it/s]\n",
      "train epoch[2/10] loss:2.294:   1%|▍                                                   | 9/938 [00:00<00:10, 85.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:14 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[2/10] loss:2.281: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 90.70it/s]\n",
      "validate epoch[2/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 123.29it/s]\n",
      "train epoch[3/10] loss:2.277:   1%|▍                                                   | 9/938 [00:00<00:10, 84.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:19 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[3/10] loss:2.274: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 91.88it/s]\n",
      "validate epoch[3/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 124.57it/s]\n",
      "train epoch[4/10] loss:2.257:   1%|▍                                                   | 9/938 [00:00<00:10, 85.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:24 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[4/10] loss:2.209: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 91.83it/s]\n",
      "validate epoch[4/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 124.67it/s]\n",
      "train epoch[5/10] loss:2.194:   1%|▍                                                   | 9/938 [00:00<00:10, 87.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:44 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[5/10] loss:2.045: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.21it/s]\n",
      "validate epoch[5/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 124.37it/s]\n",
      "train epoch[6/10] loss:2.102:   1%|▍                                                   | 9/938 [00:00<00:10, 88.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:50 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[6/10] loss:1.913: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 91.97it/s]\n",
      "validate epoch[6/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 124.22it/s]\n",
      "train epoch[7/10] loss:1.924:   1%|▍                                                   | 9/938 [00:00<00:11, 84.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:56 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[7/10] loss:1.474: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.57it/s]\n",
      "validate epoch[7/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 123.78it/s]\n",
      "train epoch[8/10] loss:1.226:   1%|▍                                                   | 9/938 [00:00<00:10, 85.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:65 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[8/10] loss:0.894: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.84it/s]\n",
      "validate epoch[8/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 123.29it/s]\n",
      "train epoch[9/10] loss:0.987:   1%|▍                                                   | 9/938 [00:00<00:11, 81.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:74 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[9/10] loss:0.760: 100%|██████████████████████████████████████████████████| 938/938 [00:10<00:00, 93.27it/s]\n",
      "validate epoch[9/10]: 100%|█████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 124.27it/s]\n",
      "train epoch[10/10] loss:0.813:   1%|▍                                                  | 9/938 [00:00<00:10, 87.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:79 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch[10/10] loss:0.752: 100%|█████████████████████████████████████████████████| 938/938 [00:10<00:00, 92.98it/s]\n",
      "validate epoch[10/10]: 100%|████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 121.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on validate set:83 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# 查看是否有cuda如果没有，则用cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "\n",
    "# 将输入数据标准化,ToTensor将数据转换为张量，Normalize将数据标准化，其中0.13047是均值，0.3081是方差，这两个数据是经验值\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../data/MNIST/', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../data/MNIST/', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "\n",
    "\n",
    "# 定义网络结构\n",
    "class FC(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.l3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.l4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.l5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# 生成全连接网络模型实例\n",
    "model = FC()\n",
    "model.to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# 训练函数\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader)\n",
    "    for data in train_bar:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播\n",
    "        outputs = model(images)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 权重更新\n",
    "        optimizer.step()\n",
    "        # 进度条描述训练进度\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                 epochs,\n",
    "                                                                 loss)\n",
    "\n",
    "     \n",
    "\n",
    "# 验证函数\n",
    "def validate(epoch):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(test_loader)\n",
    "        for data in test_bar:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # 得到预测值\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            # 判断是否预测正确\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # 进度条描述训练进度\n",
    "            test_bar.desc = \"validate epoch[{}/{}]\".format(epoch + 1,\n",
    "                                                           epochs)\n",
    "\n",
    "        print('accuracy on validate set:%d %%\\n' % (100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 训练周期\n",
    "    epochs = 20\n",
    "\n",
    "    for i in range(epochs):\n",
    "        train(i)\n",
    "\n",
    "        validate(i)\n",
    "\n",
    "    torch.save(model.state_dict(), \"fc_trained_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a5ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label       predicted\n",
      "6          5\n",
      "6          6\n",
      "0          0\n",
      "0          2\n",
      "3          3\n",
      "3          9\n",
      "9          7\n",
      "9          1\n",
      "8          8\n",
      "8          2\n",
      "5          3\n",
      "5          8\n",
      "7          1\n",
      "7          1\n",
      "2          2\n",
      "2          2\n",
      "4          1\n",
      "4          9\n",
      "1          1\n",
      "1          1\n",
      "FC trained model: accuracy on mymnist set:40 %\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class MyMnistDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "\n",
    "        self.myMnistPath = root\n",
    "        self.imagesData = []\n",
    "        self.labelsData = []\n",
    "        self.labelsDict = {}\n",
    "        self.trans = transform\n",
    "\n",
    "        self.loadLabelsDate()\n",
    "        self.loadImageData()\n",
    "\n",
    "    # 读取标签txt文件，并生成字典\n",
    "    def loadLabelsDate(self):\n",
    "        labelsPath = os.path.join(self.myMnistPath, \"labels\", \"labels.txt\")\n",
    "        f = open(labelsPath)\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            name = line.split(' ')[0]\n",
    "            label = line.split(' ')[1]\n",
    "            self.labelsDict[name] = int(label)\n",
    "\n",
    "    # 读取手写图片数据，并将图片数据和对应的标签组合在一起\n",
    "    def loadImageData(self):\n",
    "        imagesFolderPath = os.path.join(self.myMnistPath, 'images')\n",
    "        imageFiles = os.listdir(imagesFolderPath)\n",
    "\n",
    "        for imageName in imageFiles:\n",
    "            imagePath = os.path.join(imagesFolderPath, imageName)\n",
    "            image = Image.open(imagePath)\n",
    "            grayImage = image.convert(\"L\")\n",
    "\n",
    "            imageTensor = self.trans(grayImage)\n",
    "            self.imagesData.append(imageTensor)\n",
    "\n",
    "            self.labelsData.append(self.labelsDict[imageName])\n",
    "\n",
    "        self.labelsData = torch.Tensor(self.labelsData)\n",
    "\n",
    "    # 重写魔法函数\n",
    "    def __getitem__(self, index):\n",
    "        return self.imagesData[index], self.labelsData[index]\n",
    "\n",
    "    # 重写魔法函数\n",
    "    def __len__(self):\n",
    "        return len(self.labelsData)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([28, 28]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 载入自己的数据集\n",
    "dataset = MyMnistDataset(root='../data/my_mnist_dateset', transform=transform)\n",
    "test_loader = DataLoader(dataset=dataset, shuffle=False)\n",
    "\n",
    "# 生成全连接神经网络并载入训练好的模型\n",
    "model = FC()\n",
    "model.load_state_dict(torch.load(\"fc_trained_model.pth\"))\n",
    "\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(\"label       predicted\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print(\"{}          {}\".format(int(labels.item()), predicted.data.item()))\n",
    "\n",
    "        print('FC trained model: accuracy on mymnist set:%d %%' % (100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0497a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f5372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
