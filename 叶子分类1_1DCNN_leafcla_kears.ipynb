{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "122a3cf2",
   "metadata": {},
   "source": [
    "kaggle 叶子分类问题 Simple Kears 1D CNN\n",
    "输入数据在上一层的leaf_classification里 train.csv(991条)和test.csv（595条），number_class=99\n",
    "在csv文件中，特征集的保存方式nxm，其中n为样本个数，192个特征。这里有3类特征，64个magin特征， 64个shape特征， 64个texture特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae1425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "56/56 [==============================] - 23s 382ms/step - loss: 3.6651 - accuracy: 0.2458 - val_loss: 1.4632 - val_accuracy: 0.6970\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 21s 380ms/step - loss: 0.7881 - accuracy: 0.8395 - val_loss: 0.4835 - val_accuracy: 0.9091\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 21s 381ms/step - loss: 0.1401 - accuracy: 0.9675 - val_loss: 0.2206 - val_accuracy: 0.9192\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 21s 379ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.1704 - val_accuracy: 0.9394\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 21s 380ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.1975 - val_accuracy: 0.9495\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 21s 380ms/step - loss: 0.0292 - accuracy: 0.9955 - val_loss: 0.1194 - val_accuracy: 0.9596\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 21s 380ms/step - loss: 0.0251 - accuracy: 0.9944 - val_loss: 0.1803 - val_accuracy: 0.9495\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 21s 381ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1228 - val_accuracy: 0.9596\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 21s 381ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9495\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 21s 381ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1532 - val_accuracy: 0.9495\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 21s 382ms/step - loss: 0.0124 - accuracy: 0.9978 - val_loss: 0.1175 - val_accuracy: 0.9596\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 21s 381ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9596\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 21s 379ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9697\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 21s 383ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9697\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 21s 381ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9e5023b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "train = pd.read_csv('../leaf_classification/train.csv')\n",
    "test = pd.read_csv('../leaf_classification/test.csv')\n",
    "def encode(train, test):\n",
    "    label_encoder = LabelEncoder().fit(train.species)\n",
    "    labels = label_encoder.transform(train.species)\n",
    "    classes = list(label_encoder.classes_)\n",
    "\n",
    "    train = train.drop(['species', 'id'], axis=1)\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    return train, labels, test, classes\n",
    "\n",
    "train, labels, test, classes = encode(train, test)\n",
    "\n",
    "# standardize train features\n",
    "scaler = StandardScaler().fit(train.values)\n",
    "scaled_train = scaler.transform(train.values)\n",
    "\n",
    "# split train data into train and validation\n",
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\n",
    "for train_index, valid_index in sss.split(scaled_train, labels):\n",
    "    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n",
    "    y_train, y_valid = labels[train_index], labels[valid_index]\n",
    "    \n",
    "\n",
    "nb_features = 64 # number of features per features type (shape, texture, margin) \n",
    "nb_class = len(classes)\n",
    "\n",
    "# reshape train data\n",
    "X_train_r = np.zeros((len(X_train), nb_features, 3))\n",
    "X_train_r[:, :, 0] = X_train[:, :nb_features]\n",
    "X_train_r[:, :, 1] = X_train[:, nb_features:128]\n",
    "X_train_r[:, :, 2] = X_train[:, 128:]\n",
    "\n",
    "# reshape validation data\n",
    "X_valid_r = np.zeros((len(X_valid), nb_features, 3))\n",
    "X_valid_r[:, :, 0] = X_valid[:, :nb_features]\n",
    "X_valid_r[:, :, 1] = X_valid[:, nb_features:128]\n",
    "X_valid_r[:, :, 2] = X_valid[:, 128:]\n",
    "\n",
    "# Keras model with one Convolution1D layer\n",
    "# unfortunately more number of covnolutional layers, filters and filters lenght \n",
    "# don't give better accuracy\n",
    "model = Sequential()\n",
    "#model.add(Convolution1D(nb_filter=512, filter_length=1, input_shape=(nb_features, 3)))\n",
    "model.add(Convolution1D(filters=512, kernel_size=1, input_shape=(nb_features, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(nb_class))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 15\n",
    "model.fit(X_train_r, y_train, epochs=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ccb208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5fde4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227c8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb41d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d78c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
