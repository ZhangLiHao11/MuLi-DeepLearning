{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6bc6aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 导入基本库\n",
    "import cx_Oracle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import seed \n",
    "seed(1) \n",
    "#from tensorflow import set_random_seed \n",
    "#set_random_seed(2)\n",
    "\n",
    "# LabelEncoder 用来编码输出标签\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StratifiedShuffleSplit可以用来把数据集洗牌，并拆分成训练集和验证集\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 我们用的Keras支持模型创建\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,AveragePooling1D,MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5326ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../leaf_classification/train.csv')\n",
    "test = pd.read_csv('../leaf_classification/test.csv')\n",
    "def encode(train, test):\n",
    "    label_encoder = LabelEncoder().fit(train.species)\n",
    "    labels = label_encoder.transform(train.species)\n",
    "    classes = list(label_encoder.classes_)\n",
    "\n",
    "    train = train.drop(['species', 'id'], axis=1)\n",
    "    test = test.drop('id', axis=1)\n",
    "\n",
    "    return train, labels, test, classes\n",
    "train, labels, test, classes = encode(train, test)\n",
    "\n",
    "# 标准化数据集\n",
    "scaler = StandardScaler().fit(train.values)\n",
    "scaled_train = scaler.transform(train.values)\n",
    "\n",
    "# 把数据集拆分成训练集和测试集，测试集占10%\n",
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\n",
    "for train_index, valid_index in sss.split(scaled_train, labels):\n",
    "    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n",
    "    y_train, y_valid = labels[train_index], labels[valid_index]\n",
    "\n",
    "# 每个输入通道的大小是31位，一共3个通道\n",
    "nb_features = 64 \n",
    "nb_class = len(classes)\n",
    "\n",
    "#  把输入数据集reshape成keras喜欢的格式：（样本数，通道大小，通道数）\n",
    "X_train_r = np.zeros((len(X_train), nb_features, 3))\n",
    "\n",
    "# 这里的做法是先把所有元素初始化成0之后，再把刚才的数据集中的数据赋值过来\n",
    "X_train_r[:, :, 0] = X_train[:, :nb_features]\n",
    "X_train_r[:, :, 1] = X_train[:, nb_features:nb_features*2]\n",
    "X_train_r[:, :, 2] = X_train[:, nb_features*2:]\n",
    "\n",
    "# 验证集也要reshape一下\n",
    "X_valid_r = np.zeros((len(X_valid), nb_features, 3))\n",
    "X_valid_r[:, :, 0] = X_valid[:, :nb_features]\n",
    "X_valid_r[:, :, 1] = X_valid[:, nb_features:nb_features*2]\n",
    "X_valid_r[:, :, 2] = X_valid[:, nb_features*2:]\n",
    "\n",
    "# 将类别由整型标签转为onehot\n",
    "# 使用one hot编码器对类别进行“二进制化”操作\n",
    "y_train_labled=y_train\n",
    "y_valid_labled=y_valid\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_valid = np_utils.to_categorical(y_valid, nb_class)# 不写默认生成数组长度相同的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36534ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运用Keras对一维卷积实现\n",
    "model = Sequential()\n",
    "\n",
    "# 一维卷积层用了512个卷积核，输入是31*3的格式\n",
    "# 构造模型\n",
    "# 卷积层1，512个过滤器，过滤器长度为5，输入长度为nb_features，纬度为3\n",
    "with tf.name_scope('Covn-layer-1'):\n",
    "    model.add(Convolution1D(filters=512, kernel_size=5, input_shape=(nb_features, 3)))\n",
    "# 激活层1 relu函数\n",
    "with tf.name_scope('Activation-layer-1'):\n",
    "    model.add(Activation('relu'))\n",
    "# 池化层1 采用平均池化 核大小为2 pad方式为valid\n",
    "with tf.name_scope('AveragePooling-layer'):\n",
    "    model.add(AveragePooling1D(pool_size=2, strides=None, padding='valid'))\n",
    "# 卷积层2，128个过滤器，过滤器长度为5，输入长度为nb_features，纬度为3\n",
    "with tf.name_scope('Covn-layer-2'):\n",
    "    model.add(Convolution1D(filters=128, kernel_size=5, input_shape=(nb_features, 3)))\n",
    "# 激活层2 relu函数\n",
    "with tf.name_scope('Activation-layer-2'):\n",
    "    model.add(Activation('relu'))\n",
    "# 池化层1 采用最大池化 核大小为2 pad方式为valid\n",
    "with tf.name_scope('MaxPooling-layer'):\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid'))\n",
    "# 平铺层，调整维度适应全链接层\n",
    "with tf.name_scope('Dense-layer-1'):\n",
    "    model.add(Flatten())\n",
    "# 进行数据局部失活，防止过拟合\n",
    "    model.add(Dropout(0.4))\n",
    "# 全连接层\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "# 全连接层\n",
    "with tf.name_scope('Dense-layer-2'):\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "with tf.name_scope('output'):\n",
    "    model.add(Dense(nb_class))\n",
    "\n",
    "# softmax经常用来做多类分类问题\n",
    "with tf.name_scope('softmax'):\n",
    "    model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472d2ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3d6958d75384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 编译模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 采用随机梯度下降优化函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m model.compile(loss='categorical_crossentropy',\n\u001b[0;32m      5\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SGD' is not defined"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "# 采用随机梯度下降优化函数\n",
    "sgd = SGD(learning_rate=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#%% 自定义的类来保存日志记录\n",
    "# 将on_train_run作为一个类回调打印模型\n",
    "class Model_Summary(keras.callbacks.Callback):\n",
    "    def on_train_begin(self,logs=None):\n",
    "        print('On_train_begin')\n",
    "        model.summary()\n",
    "        print(keras.utils.layer_utils.print_summary(self.model))\n",
    "\n",
    "# 调用tensorboard生成模型graph\n",
    "class Model_Graph(keras.callbacks.TensorBoard):\n",
    "    tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', \n",
    "                                         histogram_freq=0, \n",
    "                                         write_graph=True, \n",
    "                                         write_images=True)\n",
    "\n",
    "# 输出损失值与正确率\n",
    "show_loss_callback = LambdaCallback(\n",
    "        on_epoch_end = lambda epoch,logs:\n",
    "            print(epoch,\n",
    "                  'loss:',logs['loss'],\n",
    "                  'acc:',logs['accuracy']))# type(epoch),type(logs['loss']),type(logs['acc'])\n",
    "\n",
    "# 回调记录损失值和变化率\n",
    "class Model_History(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accuracy = []\n",
    "        self.val_accuracy = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.val_losses.append(logs['val_loss'])\n",
    "        self.accuracy.append(logs['accuracy'])\n",
    "        self.val_accuracy.append(logs['val_accuracy'])\n",
    "    \n",
    "    # 清空画布\n",
    "    plt.close('all')\n",
    "    \n",
    "    \n",
    "    # 显示损失值变化情况\n",
    "    def show_losss(self):\n",
    "        plt.figure(1)\n",
    "        plt.plot(np.arange(len(self.losses)),self.losses,label='loss')\n",
    "        plt.plot(np.arange(len(self.val_losses)),self.val_losses,label='val_loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.title('model loss')\n",
    "       \n",
    "        \n",
    "    # 显示正确率变化情况\n",
    "    def show_accuracy(self):\n",
    "        plt.figure(2)\n",
    "        plt.plot(np.arange(len(self.accuracy)),self.accuracy,label='accuracy')\n",
    "        plt.plot(np.arange(len(self.val_accuracy)),self.val_accuracy,label='val_accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.title('model accuracy')\n",
    "        \n",
    "#%%\n",
    "#用于实现callback 保存日志记录   \n",
    "history = Model_History()\n",
    "\n",
    "#%%\n",
    "\n",
    "# 模型训练的轮数\n",
    "nb_epoch =50\n",
    "patience = 4\n",
    "# 训练模型\n",
    "model_history = model.fit(X_train_r, y_train, \n",
    "                    batch_size=16,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid_r, y_valid),\n",
    "                    # 是否在训练过程中随机打乱输入样本的顺序\n",
    "                    shuffle=True,\n",
    "                    #callbacks = [Model_Summary(),\n",
    "                                # Model_Graph(),\n",
    "                                 #EarlyStopping(patience=patience,mode='min',verbose=0),\n",
    "                                 #show_loss_callback,\n",
    "                                 #history]\n",
    "                         )\n",
    "score = model.evaluate(X_valid_r, y_valid, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "history.show_losss()\n",
    "history.show_accuracy()\n",
    "#\n",
    "#model.save('D:\\python\\workspace\\well\\classical_model_epoch'+str(nb_epoch)+'.h5')   \n",
    "#model.save_weights('D:\\python\\workspace\\well\\classical_model_weight_epoch'+str(nb_epoch)+'.h5')\n",
    "\n",
    "#%%\n",
    "# 进行预测\n",
    "pred_y = model.predict(X_train_r)\n",
    "#pre_result=np.print(pred_y)\n",
    "result=list(pred_y.nonzero())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a34bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40424bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf495e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a114357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8879e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f3568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c63e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce9187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f462de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a185487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a86d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
